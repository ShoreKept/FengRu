
Load Dataset
label column: label
label dictionary: {'Normal': 0, '19DEL': 1, 'L858R': 2, 'Other': 3, 'Wild': 4}
number of classes: 5
slide-level counts:  
 label
0    163
2    183
3    138
1    116
4    142
Name: count, dtype: int64
Patient-LVL; Number of samples registered in class 0: 163
Slide-LVL; Number of samples registered in class 0: 163
Patient-LVL; Number of samples registered in class 1: 116
Slide-LVL; Number of samples registered in class 1: 116
Patient-LVL; Number of samples registered in class 2: 183
Slide-LVL; Number of samples registered in class 2: 183
Patient-LVL; Number of samples registered in class 3: 138
Slide-LVL; Number of samples registered in class 3: 138
Patient-LVL; Number of samples registered in class 4: 142
Slide-LVL; Number of samples registered in class 4: 142
split_dir:  /home/graduate2024/code/zxb/CLAM-master/splits/EGFR_Five_subtyping_fengru_100
################# Settings ###################
num_splits:  10
k_start:  -1
k_end:  -1
task:  EGFR_Five_subtyping_fengru
max_epochs:  200
results_dir:  /home/graduate2024/code/zxb/CLAM-master/results/N_EGFR_Five_UNI_d1024
lr:  0.0002
experiment:  N_EGFR_Five_subtyping_fengru
reg:  1e-05
label_frac:  1.0
bag_loss:  ce
seed:  1
model_type:  clam_mb
model_size:  small
use_drop_out:  0.25
weighted_sample:  True
opt:  adam
bag_weight:  0.7
inst_loss:  svm
B:  8
split_dir:  /home/graduate2024/code/zxb/CLAM-master/splits/EGFR_Five_subtyping_fengru_100

Training Fold 0!

Init train/val/test splits... 
Done!
Training on 594 samples
Validating on 74 samples
Testing on 74 samples

Init loss function... Done!

Init Model... Setting tau to 1.0
Done!
Model__:
CLAM_MB(
  (attention_net): Sequential(
    (0): Linear(in_features=1024, out_features=512, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.25, inplace=False)
    (3): Attn_Net_Gated(
      (attention_a): Sequential(
        (0): Linear(in_features=512, out_features=256, bias=True)
        (1): Tanh()
        (2): Dropout(p=0.25, inplace=False)
      )
      (attention_b): Sequential(
        (0): Linear(in_features=512, out_features=256, bias=True)
        (1): Sigmoid()
        (2): Dropout(p=0.25, inplace=False)
      )
      (attention_c): Linear(in_features=256, out_features=5, bias=True)
    )
  )
  (classifiers): ModuleList(
    (0-4): 5 x Linear(in_features=512, out_features=1, bias=True)
  )
  (instance_classifiers): ModuleList(
    (0-4): 5 x Linear(in_features=512, out_features=2, bias=True)
  )
  (instance_loss_fn): SmoothTop1SVM()
)
Total number of parameters: 796436
Total number of trainable parameters: 796436

Init optimizer ... Done!

Init Loaders... Done!

Setup EarlyStopping... Done!


